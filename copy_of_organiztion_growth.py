# -*- coding: utf-8 -*-
"""Copy of organiztion_growth.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Clope2qGGsof8K-TrbFsDIMNpYBW_NYB
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
from matplotlib import pyplot as plt
# %matplotlib inline
import numpy as np
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

"""**Goal is to predict which employees are at high risk of churn**"""

!pip install opendatasets
import opendatasets as od
od.download('https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset')



#loading the dataset
df=pd.read_csv('/content/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')
df.head(5)

df.info()

"""There are no null values in any of the columns. Attrition is our target variable."""

df.describe(include='all').T

#dropping these columns because they are of no use for prediction
df=df.drop(['EmployeeCount','EmployeeNumber','Over18','StandardHours'],axis=1)
df

columns=list(df.columns)
columns

categorical=[data for data in columns if df[data].dtype=='object']
categorical

numerical=[data for data in df.columns if df[data].dtypes!='object']
numerical

#categorical variables vs Attrition
for data in categorical:
 print(pd.crosstab(df[data],df['Attrition'],margins=True))
 print('***********************************************')

#count plots for categorical variables
for i in categorical:
 plt.figure(figsize=(20,15))
 sns.countplot(x=i,hue='Attrition',data=df)
 
 plt.show()

"""1. Gender: Male employees quit more than female employees.
2. Business Travel: The employees who travel rarely are more likely to quit than other employees.
3. Marital Status: Employees who are single tend to quit their jobs more than the married or divorced.
4. Department: Research and Development employees don't quit their jobs as much as the other departments.
5. Job Role: Sales Executives, Laboratory Technicians and Research Scientists are more likely to quit than other employees.
6. Education Field: Employees from Life Sciences, Medical and Marketing educational background are more likely to stay than other employees of different educational background.
7. Over Time: Employees who do over time, quit more.
"""

numerical

#plots for discrete numerical variables
numerical_selected=['Age',
 'DistanceFromHome',
 'Education',
 'EnvironmentSatisfaction',
 'JobInvolvement',
 'JobLevel',
 'JobSatisfaction',
 'NumCompaniesWorked',
 'PercentSalaryHike',
 'PerformanceRating',
 'RelationshipSatisfaction',
 'StockOptionLevel',
 'TotalWorkingYears',
 'TrainingTimesLastYear',
 'WorkLifeBalance',
 'YearsAtCompany',
 'YearsInCurrentRole',
 'YearsSinceLastPromotion',
 'YearsWithCurrManager']

for i in numerical_selected:
 plt.figure(figsize=(10,8))
 sns.countplot(x=i,hue='Attrition',data=df)
 
 plt.show()

import plotly.express as px
fig=px.strip(df,x='MonthlyIncome',y='Attrition',orientation='h',color='Attrition')
fig.show()

"""1. Young employees aged below 22 yrs, quit their jobs more than the rest.
2. Employees who travel more than 10 kms to reach office, are more likely to quit.
3. Environment Satisfaction, Job Satisfaction, Relationship Satisfaction, Job Involvement, Performance Rating, Stock Option Level, Work Life Balance: these features don't really help us in understanding the employees' attrition.
4. Employees with low Job Level, Monthly Income, Percent Salary Hike, Total Working Years, Years At Company are prone to quitting their jobs.
5. Employees who have worked in less than 2 comapanies, are more likely to stay.
6. Employees who have received promotion recently within 2 years, will stay than employees who haven't received any promotion for a long time.
7. Employees who have spent more than 2 years with their current manager, are more likely to stay.
"""

df.corr()

plt.figure(figsize=(15,10))

sns.heatmap(df.corr(),annot=True,fmt='.2f',linewidths=0.2,vmax=1,vmin=-1)
plt.show()

"""Observations :

1. Job Level and Monthly Income are highly correlated.
2. Monthly Income is highly correlated with Total Working Hours.
3. Job Level and Total Working Hours are highly correlated.
4. Performance Rating is highly correlated with Percent Salary Hike.
5. Years in Current Role and Years with Current Manager has high correlation with Years at Company.
"""

#box plot for different numeric variables vs attrition to study about the outliers present in the dataset
for i in numerical_selected:
 plt.figure(figsize=(10,8))
 sns.boxplot(x=df['Attrition'],y=df[i],data=df)
 
 plt.show()

"""Observation :

Outliers are there but it will not effect our model.

# Data Processing
"""

df.head(1)

X=df.drop('Attrition',axis=1)
Y=df['Attrition']
print(X.shape)
print(Y.shape)

#selecting out discrete continuous variables for encoding
columns_to_encode= []
for i in X.columns:
    if df[i].nunique() <20:
        columns_to_encode.append(i)
        
columns_to_encode

#one hot encoding
df_encoded=pd.get_dummies(X,columns=columns_to_encode,drop_first=True)
X=df_encoded
X

df_encoded.shape

#encoding the target variable
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()

Y=le.fit_transform(Y)
Y=pd.DataFrame(Y)
Y=Y.rename(columns={0:'Attrition'})
Y

Y['Attrition'].value_counts()

"""Observation :
1. There is a huge difference between the total number of examples in the dataset having attrition 0 and attrition 1
"""

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42,stratify=Y)

#feature scaling
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
X_train_std=scaler.fit_transform(X_train)
X_test_std=scaler.transform(X_test)

X_train_std=pd.DataFrame(X_train_std)
X_train_std.columns=X.columns

X_test_std=pd.DataFrame(X_test_std)
X_test_std.columns=X.columns

X_train_std = X_train_std.to_numpy()

X_test_std = X_test_std.to_numpy()

"""# Model fitting"""

X_train_std.shape

"""# Xception"""

import pandas as pd
import numpy as np
from tensorflow.keras.applications.inception_v3 import InceptionV3 as GoogleNet
import tensorflow as tf
from tensorflow.keras.applications.xception import Xception
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.models import Model
from keras.models import Sequential

X_train_std = X_train_std.reshape(-1, 135, 1)
X_test_std = X_test_std.reshape(-1, 135, 1)

# Define the input shape
input_shape = (135, 1,1)

# Define the model architecture
base_model = Xception(input_shape=(224,224,3), include_top=False)
x = base_model.output
x = Flatten()(x)
x = Dense(128, activation='relu')(x)
predictions = Dense(1, activation='sigmoid')(x)
model = Model(inputs=base_model.input, outputs=predictions)

model = Sequential()
model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train_std, Y_train, epochs=10, batch_size=128, validation_data=(X_test_std, Y_test))

"""# Inception"""

from tensorflow.keras.applications.inception_v3 import InceptionV3
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications.xception import Xception
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.models import Model
from keras.models import Sequential

X_train_std = X_train_std.reshape(-1, 135, 1)
X_test_std = X_test_std.reshape(-1, 135, 1)

# Define the input shape
input_shape = (135, 1,1)

# Define the model architecture
base_model = InceptionV3(input_shape=(224,224,3), include_top=False)
x = base_model.output
x = Flatten()(x)
x = Dense(128, activation='relu')(x)
predictions = Dense(1, activation='sigmoid')(x)
model = Model(inputs=base_model.input, outputs=predictions)

model = Sequential()
model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(8, activation='relu')) 
# model.add(Dense(2, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train_std, Y_train, epochs=20, batch_size=16)

"""# from tensorflow.keras.applications.googlenet import GoogLeNet"""

# from tensorflow.keras.applications.googlenet import GoogLeNet
# from tensorflow.keras.applications.inception_v3 import InceptionV3
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications.xception import Xception
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.models import Model
from keras.models import Sequential

X_train_std = X_train_std.reshape(-1, 135, 1)
X_test_std = X_test_std.reshape(-1, 135, 1)

# Define the input shape
input_shape = (135, 1,1)

# Define the model architecture
base_model = GoogleNet(input_shape=(224,224,3), include_top=False)
x = base_model.output
x = Flatten()(x)
x = Dense(128, activation='relu')(x)
predictions = Dense(1, activation='sigmoid')(x)
model = Model(inputs=base_model.input, outputs=predictions)

model = Sequential()
model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))
model.add(Dense(20, activation='relu'))
model.add(Dense(8, activation='relu')) 
# model.add(Dense(2, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train_std, Y_train, epochs=20, batch_size=16, validation_data=(X_test_std, Y_test))

"""# Densenet

"""



X_train_std = X_train_std.reshape(-1, 135, 1)
X_test_std = X_test_std.reshape(-1, 135, 1)

# Define the input shape
input_shape = (135, 1,1)

# Define the model architecture
base_model = tf.keras.applications.DenseNet201(input_shape=(224,224,3), include_top=False)
x = base_model.output
x = Flatten()(x)
x = Dense(128, activation='relu')(x)
predictions = Dense(1, activation='sigmoid')(x)
model = Model(inputs=base_model.input, outputs=predictions)

model = Sequential()
model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))
model.add(Dense(20, activation='relu'))
model.add(Dense(8, activation='relu')) 
# model.add(Dense(2, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train_std, Y_train, epochs=20, batch_size=16, validation_data=(X_test_std, Y_test))

"""# Alexnet"""

from tensorflow import keras

model=keras.models.Sequential([
    keras.layers.Conv2D(filters=128, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(64,64,3)),
    keras.layers.BatchNormalization(),
    keras.layers.MaxPool2D(pool_size=(2,2)),
    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.MaxPool2D(pool_size=(3,3)),
    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.MaxPool2D(pool_size=(2,2)),
    keras.layers.Flatten(),
    keras.layers.Dense(1024,activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(1024,activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(10,activation='softmax')  
    
    
])
model = Sequential()
model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))
model.add(Dense(20, activation='relu'))
model.add(Dense(8, activation='relu')) 
# model.add(Dense(2, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train_std, Y_train, epochs=20, batch_size=16, validation_data=(X_test_std, Y_test))

import matplotlib.pyplot as plt
plt.bar(['Inception', 'Xception'],[99.74, 81.64])

import matplotlib.pyplot as plt
plt.bar(['Inception', 'GoogleNet'],[99.74, 84.69])

import matplotlib.pyplot as plt
plt.bar(['Inception', 'ALexnet'],[99.74, 85.71])

import matplotlib.pyplot as plt
plt.bar(['Inception', 'Densenet'],[99.74, 83.67])